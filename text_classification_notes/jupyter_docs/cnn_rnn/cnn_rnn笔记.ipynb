{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "增加两个参数 rnn_hidden_size=128, rnn_seq_len=4  \n",
    "rnn_hidden_size代表rnn隐藏层的大小，rnn_seq_len这里代表rnn展开长度  \n",
    "增加batch_size的placeholder，用于变长的batch_size  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class TextModel(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "        data, target,\n",
    "        max_sequence_len, vocab_size, embedding_size, filter_sizes, num_filters,\n",
    "        rnn_hidden_size=128,\n",
    "        rnn_seq_len=4,\n",
    "        num_classes=2,\n",
    "        embedding_init=None,\n",
    "        l2_reg_lambda=0.0,\n",
    "        learning_rate=1e-3\n",
    "        ):\n",
    "        \"\"\"\n",
    "        __init__\n",
    "        \"\"\"\n",
    "        # inputs, placeholder\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "        self.batch_size = tf.placeholder(tf.int32, [])\n",
    "        # model configs\n",
    "        self._num_classes = num_classes\n",
    "        self._max_sequence_len = max_sequence_len\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_size = embedding_size\n",
    "        self._filter_sizes = filter_sizes\n",
    "        self._num_filters = num_filters\n",
    "        self._rnn_hidden_size = rnn_hidden_size\n",
    "        self._rnn_seq_len = rnn_seq_len\n",
    "        self._l2_reg_lambda = l2_reg_lambda\n",
    "        self._learning_rate = learning_rate\n",
    "        # model ops\n",
    "        self._scores = None\n",
    "        self._prediction = None\n",
    "        self.l2_loss = None\n",
    "        self._loss = None\n",
    "        self._accuracy = None\n",
    "        self._optimize = None\n",
    "        self._error = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：  \n",
    "https://www.kaggle.com/dskswu/cnn-lstm-neural-network?scriptVersionId=1999299/notebook  \n",
    "https://stackoverflow.com/questions/40960200/understanding-cnn-lstm-rnn-in-tensorflow  \n",
    "\n",
    "https://blog.csdn.net/u012436149/article/details/52887091  \n",
    "https://segmentfault.com/a/1190000008793389  \n",
    "https://zhuanlan.zhihu.com/p/28196873  \n",
    "https://feisky.xyz/machine-learning/rnn/sequence.html  \n",
    "https://blog.csdn.net/u010223750/article/details/71079036  \n",
    "https://github.com/jiegzhan/multi-class-text-classification-cnn-rnn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    @property\n",
    "    def scores(self):\n",
    "        \"\"\"\n",
    "        score\n",
    "        \"\"\"\n",
    "        if self._scores is None:\n",
    "            # embedding_layer\n",
    "            with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "                self.W = tf.Variable(\n",
    "                            tf.random_uniform([self._vocab_size, self._embedding_size], -1.0, 1.0),\n",
    "                            name=\"W\")\n",
    "                self.embedded = tf.nn.embedding_lookup(self.W, self.data)\n",
    "                self.embedded_expanded = tf.expand_dims(self.embedded, -1)  # expend dims to 4d for conv layer\n",
    "            # create a convolution + maxpool layer for each filter size\n",
    "            pooled_outputs = []\n",
    "            for i, filter_size in enumerate(self._filter_sizes):\n",
    "                with tf.name_scope(\"conv-maxpool-{0}\".format(filter_size)):\n",
    "                    # convolution layer\n",
    "                    filter_shape = [filter_size, self._embedding_size, 1, self._num_filters]\n",
    "                    print(\"conv-maxpool-{0}.filter_size {1}\".format(filter_size, filter_shape))\n",
    "                    W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "                    b = tf.Variable(tf.constant(0.1, shape=[self._num_filters]), name=\"b\")\n",
    "                    conv = tf.nn.conv2d(\n",
    "                            self.embedded_expanded,\n",
    "                            W,\n",
    "                            strides=[1, 1, 1, 1],\n",
    "                            padding=\"VALID\",\n",
    "                            name=\"conv\")\n",
    "                    # apply nonlinearity\n",
    "                    h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                    # maxpooling over the outputs\n",
    "                    pooled = tf.nn.max_pool(\n",
    "                                h,\n",
    "                                ksize=[1, self._max_sequence_len - filter_size + 1, 1, 1],\n",
    "                                strides=[1, 1, 1, 1],\n",
    "                                padding=\"VALID\",\n",
    "                                name=\"pool\")\n",
    "                    pooled_outputs.append(pooled)\n",
    "            # combine all the pooled features\n",
    "            num_filters_total = self._num_filters * len(self._filter_sizes)\n",
    "            print(\"num_filters_total {0}\".format(num_filters_total))\n",
    "            self.h_pool = tf.concat(pooled_outputs, 3)  # (?, 1, 1, 384)\n",
    "            #self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "            # flatten before rnn\n",
    "            dims = self.h_pool.get_shape()\n",
    "            print(\"h_pool.get_shape {0}\".format(dims)) # h_pool.get_shape (?, 1, 1, 384)\n",
    "            print(\"self._rnn_seq_len {0}\".format(self._rnn_seq_len))\n",
    "            number_of_elements = int(dims[1:].num_elements() / self._rnn_seq_len) # 384 / 4\n",
    "            self.h_pool_flat = tf.reshape(self.h_pool, [self.batch_size, int(self._rnn_seq_len), number_of_elements])\n",
    "            # add dropout\n",
    "            with tf.name_scope(\"dropout\"):\n",
    "                self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "            print(\"self.h_drop.shape {}\".format(self.h_drop.shape))\n",
    "            with tf.name_scope(\"rnn\"):\n",
    "                # many cell types to choose\n",
    "                # cell = tf.nn.rnn_cell.LSTMCell\n",
    "                # cell = tf.nn.rnn_cell.GRUCell\n",
    "                # cell = tf.nn.rnn_cell.BasicRNNCell\n",
    "                cell = tf.nn.rnn_cell.LSTMCell(self._rnn_hidden_size)\n",
    "                self._initial_state = cell.zero_state(self.batch_size, tf.float32)\n",
    "                # build rnn networks, maybe sequence_length is needed\n",
    "                outputs, states = tf.nn.dynamic_rnn(\n",
    "                                            cell=cell,\n",
    "                                            inputs=self.h_drop,\n",
    "                                            initial_state=self._initial_state)\n",
    "                # flatten the final output of the rnn\n",
    "                print(\"outputs.shape {0}\".format(outputs.shape))  # (?, 4, 128)\n",
    "                self.rnn_output = outputs[:, -1, :]\n",
    "                print(\"self.rnn_output.shape {0}\".format(self.rnn_output.shape))\n",
    "            # final (unnormalized) scores and predictions\n",
    "            with tf.name_scope(\"net_output\"):\n",
    "                W = tf.get_variable(\n",
    "                        \"W\",\n",
    "                        shape=[self._rnn_hidden_size, self._num_classes],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[self._num_classes]), name=\"b\")\n",
    "                # may be get some loss here?\n",
    "                self.l2_loss = tf.nn.l2_loss(W) + tf.nn.l2_loss(b)\n",
    "                self._scores = tf.nn.xw_plus_b(self.rnn_output, W, b, name=\"scores\")\n",
    "                # define prediction\n",
    "                self._prediction = tf.argmax(self._scores, 1, name=\"predictions\")\n",
    "        # return scores\n",
    "        return self._scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
